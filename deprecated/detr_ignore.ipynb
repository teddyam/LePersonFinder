{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbeddingSine(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a more standard version of the position embedding, very similar to the one\n",
    "    used by the Attention is all you need paper, generalized to work on images.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_pos_feats=64, temperature=10000, normalize=False, scale=None):\n",
    "        super().__init__()\n",
    "        self.num_pos_feats = num_pos_feats\n",
    "        self.temperature = temperature\n",
    "        self.normalize = normalize\n",
    "        if scale is not None and normalize is False:\n",
    "            raise ValueError(\"normalize should be True if scale is passed\")\n",
    "        if scale is None:\n",
    "            scale = 2 * math.pi\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, tensor_list: NestedTensor):\n",
    "        x = tensor_list.tensors\n",
    "        mask = tensor_list.mask\n",
    "        assert mask is not None\n",
    "        not_mask = ~mask\n",
    "        y_embed = not_mask.cumsum(1, dtype=torch.float32)\n",
    "        x_embed = not_mask.cumsum(2, dtype=torch.float32)\n",
    "        if self.normalize:\n",
    "            eps = 1e-6\n",
    "            y_embed = y_embed / (y_embed[:, -1:, :] + eps) * self.scale\n",
    "            x_embed = x_embed / (x_embed[:, :, -1:] + eps) * self.scale\n",
    "\n",
    "        dim_t = torch.arange(self.num_pos_feats, dtype=torch.float32, device=x.device)\n",
    "        dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n",
    "\n",
    "        pos_x = x_embed[:, :, :, None] / dim_t\n",
    "        pos_y = y_embed[:, :, :, None] / dim_t\n",
    "        pos_x = torch.stack((pos_x[:, :, :, 0::2].sin(), pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3)\n",
    "        pos_y = torch.stack((pos_y[:, :, :, 0::2].sin(), pos_y[:, :, :, 1::2].cos()), dim=4).flatten(3)\n",
    "        pos = torch.cat((pos_y, pos_x), dim=3).permute(0, 3, 1, 2)\n",
    "        return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: Backbone class? Backbone consists of: \n",
    "    # 1. FrozenBatchNorm2D\n",
    "    # 2. BackboneBase \n",
    "    # 3. Backbone \n",
    "        # When called, this class returns a Dict of nested Tensors (dict of Feature maps)\n",
    "    # 4. Joiner\n",
    "        # This class will call Backbone: self[0]\n",
    "        # Init two lists: out (output feat maps), pos (pos embeddings for each feat map)\n",
    "        # BackBone will return a dict of Nested Tensors:\n",
    "            # Iterate over the dictionary: \n",
    "                # Append to out \n",
    "                # Append pos embeddings to pos  \n",
    "        # Return out, pos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(nn.Module): \n",
    "    def __init__(): \n",
    "        super().__init__()\n",
    "        pass \n",
    "    def forward(samples):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: what is nn.Module? \n",
    "# A: base class for all neural network modules. All models should subclass this class\n",
    "\n",
    "class DETR(nn.Module): \n",
    "    '''\n",
    "    This class is the DETR module that performs object detection.\n",
    "    '''\n",
    "    def __init__(self, backbone, transformer, num_classes, num_queries, aux_loss=False): \n",
    "        super().__init__() \n",
    "    \n",
    "    def forward(samples): \n",
    "        # Samples is tuple of: \n",
    "            # Samples: [batch_sz, 3, H, W]\n",
    "            # Binary mask: [batch_sz, H, W]\n",
    "        # 1. First, pass this tuple -> the backbone, which was pre-built and passed to this module beforehand \n",
    "            # .build_backbone() will a) instantiate a Backbone, b) instantiate a Joiner, which takes in a Backbone -> model\n",
    "        # 2. Then extract the tuple of: Samples, Mask from backbone out list (not the pos list) SPECIFICALLY the last one...\n",
    "            # Pass in => Transformer model \n",
    "                # 1. Projection of the Samples\n",
    "                # 2. Mask\n",
    "                # 3. Take the last pos embedding too...(corresponding to inputs)\n",
    "        # 3. Then you will take the output of the Transformer => the following: \n",
    "            # 1. Pass into an embed class => outputs the class \n",
    "            # 2. Pass into a coords class => outputs the coords \n",
    "        # 4. Init a dictionary for logits and boxes and then just return that\n",
    "        pass "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
